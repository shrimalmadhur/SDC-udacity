{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import math\n",
    "from matplotlib.pyplot import imsave\n",
    "from matplotlib import pylab\n",
    "\n",
    "from scipy.signal import find_peaks_cwt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #reading in an image\n",
    "image = mpimg.imread('camera_cal/calibration1.jpg')\n",
    "# # image = mpimg.imread('test_images/straight_lines1.jpg')\n",
    "# #printing out some stats and plotting\n",
    "# print('This image is:', type(image), 'with dimesions:', image.shape)\n",
    "# plt.imshow(image)  #call as plt.imshow(gray, cmap='gray') to show a grayscaled image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_images(image, path):\n",
    "#     for img in images:\n",
    "    image.save(path)\n",
    "        \n",
    "def plot_on_subplots(images, titles, cmap=None):\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "    \n",
    "    if cmap:\n",
    "        ax1.imshow(images[0], cmap=cmap)\n",
    "    else:\n",
    "        ax1.imshow(images[0])\n",
    "    ax1.set_title(titles[0])\n",
    "\n",
    "    if(cmap):\n",
    "        ax2.imshow(images[1], cmap=cmap)\n",
    "    else:\n",
    "        ax2.imshow(images[1])\n",
    "        \n",
    "    ax2.set_title(titles[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the camera calibration matrix and distortion coefficients given a set of chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getChessBoardPoints(path):\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((6*9,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d points in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "    # Make a list of calibration images\n",
    "    images = glob.glob(path)\n",
    "\n",
    "    # Step through the list and search for chessboard corners\n",
    "    for fname in images:\n",
    "    #     print(fname)\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "        # If found, add object points, image points\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "\n",
    "            # Draw and display the corners\n",
    "#             img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "#             cv2.imshow('img',img)\n",
    "#             cv2.waitKey(500)\n",
    "\n",
    "#     cv2.destroyAllWindows()\n",
    "    return objpoints, imgpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDistortionCoeff(image, objpoints, imgpoints):\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, image.shape[0:2], None, None)\n",
    "    return dist, mtx\n",
    "\n",
    "def getUndistortedArray(images, dist, mtx):\n",
    "    img_arr = []\n",
    "    for img in images:\n",
    "        img_arr.append(undistort(img, dist, mtx))\n",
    "        \n",
    "    return np.asarray(img_arr)\n",
    "\n",
    "def undistort(img, dist, mtx):\n",
    "    return cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\n",
    "def read_images(path):\n",
    "    images = glob.glob(path)\n",
    "    imges_array = []\n",
    "    for img in images:\n",
    "        img = cv2.imread(img);\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        imges_array.append(img)\n",
    "        \n",
    "    return np.asarray(imges_array);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "objpoints, imgpoints = getChessBoardPoints('./camera_cal/calibration*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dist, mtx = getDistortionCoeff(image, objpoints, imgpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_images = read_images('./test_images/*')\n",
    "image_to_test = raw_images[5]\n",
    "undistorted_chess = undistort(image, dist, mtx)\n",
    "plot_on_subplots([image, undistorted_chess], ['Original calibration image', 'Undistorted calibration image'])\n",
    "# pylab.savefig(\"./output_images/calibrated.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_on_subplots([image_to_test, undistort(image_to_test, dist, mtx)], ['Original', 'Undistorted'])\n",
    "# pylab.savefig(\"./output_images/input_images.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def abs_sobel_thresh(img, orient='x', sobel_kernel=3, thresh=(0, 255)):\n",
    "        \n",
    "    # Apply x or y gradient with the OpenCV Sobel() function\n",
    "    # and take the absolute value\n",
    "    if orient == 'x':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=sobel_kernel))\n",
    "    if orient == 'y':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=sobel_kernel))\n",
    "    # Rescale back to 8 bit integer\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    # Create a copy and apply the threshold\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    # Here I'm using inclusive (>=, <=) thresholds, but exclusive is ok too\n",
    "    binary_output[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "\n",
    "    # Return the result\n",
    "    return binary_output\n",
    "\n",
    "def mag_thresh(img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    \n",
    "    # Apply the following steps to img\n",
    "    # Take both Sobel x and y gradients\n",
    "    sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Calculate the gradient magnitude\n",
    "    gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    # Rescale to 8 bit\n",
    "    scale_factor = np.max(gradmag)/255 \n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8) \n",
    "    # Create a binary image of ones where threshold is met, zeros otherwise\n",
    "    binary_output = np.zeros_like(gradmag)\n",
    "    binary_output[(gradmag >= mag_thresh[0]) & (gradmag <= mag_thresh[1])] = 1\n",
    "    \n",
    "    return binary_output\n",
    "\n",
    "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    # gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Calculate the x and y gradients\n",
    "    sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Take the absolute value of the gradient direction, \n",
    "    # apply a threshold, and create a binary image result\n",
    "    absgraddir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "    binary_output =  np.zeros_like(absgraddir)\n",
    "    binary_output[(absgraddir >= thresh[0]) & (absgraddir <= thresh[1])] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return binary_output\n",
    "\n",
    "def color_thresh(img, thresh=(0, 255)):\n",
    "    binary = np.zeros_like(img)\n",
    "    binary[(img >= thresh[0]) & (img <= thresh[1])] = 1\n",
    "    return binary;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_thresholded_image(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    gray_mag_thresh = mag_thresh(gray, 3, (90, 180))\n",
    "    hls_s_thresh = color_thresh(hls[:,:,2], (180, 255))\n",
    "    red_thresh = color_thresh(image[:,:,0], (220, 255))\n",
    "    dir_thresh = dir_threshold(gray, 3, (1.5, np.pi/2))\n",
    "    \n",
    "    sobelx = abs_sobel_thresh(gray, 'x', 3, (30, 255))\n",
    "    hls_l_thresh = color_thresh(hls[:,:,1], (210, 255))\n",
    "#     color_binary = np.dstack(( np.zeros_like(gray_mag_thresh), gray_mag_thresh, hls_s_thresh))\n",
    "\n",
    "    # Combine the two binary thresholds\n",
    "    combined_binary = np.zeros_like(gray_mag_thresh)\n",
    "    combined_binary[(hls_s_thresh == 1) | (gray_mag_thresh == 1) | (hls_s_thresh == 1) | (sobelx == 1) | (red_thresh == 1)] = 1\n",
    "    return combined_binary\n",
    "\n",
    "gray = cv2.cvtColor(image_to_test, cv2.COLOR_RGB2GRAY)\n",
    "hls = cv2.cvtColor(image_to_test, cv2.COLOR_RGB2HLS)\n",
    "\n",
    "gray_mag_thresh = mag_thresh(gray, 3, (90, 180))\n",
    "hls_s_thresh = color_thresh(hls[:,:,2], (180, 255))\n",
    "red_thresh = color_thresh(image_to_test[:,:,0], (220, 255))\n",
    "# plot_on_subplots([gray_mag_thresh, hls_s_thresh], [\"gray mag\", \"s thresh\"], cmap='gray')\n",
    "# pylab.savefig(\"./output_images/mag_hls_s.png\")\n",
    "plt.imshow(red_thresh, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sobelx = abs_sobel_thresh(gray, 'x', 5, (30, 255))\n",
    "plt.imshow(sobelx, cmap='gray')\n",
    "# imsave(\"./output_images/sobelx.png\", sobelx, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hls_l_thresh = color_thresh(hls[:,:,1], (210, 255))\n",
    "plt.imshow(hls_l_thresh, cmap='gray')\n",
    "# imsave(\"./output_images/hls_l_thresh.png\", hls_l_thresh, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dir_thresh = dir_threshold(gray, 3, (1.5, np.pi/2))\n",
    "\n",
    "\n",
    "# color_binary = np.dstack(( np.zeros_like(gray_mag_thresh), gray_mag_thresh, hls_s_thresh))\n",
    "\n",
    "# Combine the two binary thresholds\n",
    "combined_binary = np.zeros_like(gray_mag_thresh)\n",
    "combined_binary[(hls_s_thresh == 1) | (gray_mag_thresh == 1) | (sobelx == 1) | (hls_l_thresh == 1) | (red_thresh == 1)] = 1\n",
    "plot_on_subplots([dir_thresh, combined_binary], [\"dir threshold\", \"combined\"], cmap='gray')\n",
    "# imsave(\"./output_images/dir_thresh.png\", dir_thresh, cmap=\"gray\")\n",
    "# imsave(\"./output_images/combined_binary.png\", combined_binary, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hough lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grayscale(img):\n",
    "    \"\"\"Applies the Grayscale transform\n",
    "    This will return an image with only one color channel\n",
    "    but NOTE: to see the returned image as grayscale\n",
    "    you should call plt.imshow(gray, cmap='gray')\"\"\"\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    \"\"\"Applies the Canny transform\"\"\"\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=5):\n",
    "    \n",
    "#     for line in lines:\n",
    "#         for x1,y1,x2,y2 in line:\n",
    "#             cv2.line(img, (x1, y1), (x2, y2), [0, 255, 0], 5)\n",
    "    \n",
    "    right_lines = []\n",
    "    left_lines = []\n",
    "    y_max = image.shape[0]\n",
    "    y_min = image.shape[0]\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            if y1 < y_min:\n",
    "                y_min = y1\n",
    "                \n",
    "            if y2 < y_min:\n",
    "                y_min = y2\n",
    "    y_min = image.shape[0] * 0.7        \n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            slope = (y2-y1)/(x2-x1)\n",
    "            if slope > 0.0 and slope < np.inf:\n",
    "                right_lines.append(line)\n",
    "            elif slope < 0.0 and slope > -np.inf:\n",
    "                left_lines.append(line)\n",
    "                \n",
    "    left_line_avg = np.mean(left_lines, axis=0)\n",
    "    right_line_avg = np.mean(right_lines, axis=0)\n",
    "#     print(left_line_avg)\n",
    "#     print(left_line_avg[0][3])\n",
    "    slope_left = (left_line_avg[0][3] - left_line_avg[0][1])/(left_line_avg[0][2] - left_line_avg[0][0])\n",
    "    slope_right = (right_line_avg[0][3] - right_line_avg[0][1])/(right_line_avg[0][2] - right_line_avg[0][0])\n",
    "    \n",
    "    new_x1_left = left_line_avg[0][0] - (left_line_avg[0][1] - y_min)/slope_left\n",
    "    new_x2_left = left_line_avg[0][2] + (y_max - left_line_avg[0][3])/slope_left\n",
    "    \n",
    "    new_x1_right = right_line_avg[0][0] - (right_line_avg[0][1] - y_min)/slope_right\n",
    "    new_x2_right = right_line_avg[0][2] + (y_max - right_line_avg[0][3])/slope_right\n",
    "    \n",
    "    \n",
    "    line1 = (int(new_x1_left), y_min, int(new_x2_left), y_max)\n",
    "    line2 = (int(new_x1_right), y_min, int(new_x2_right), y_max)\n",
    "    cv2.line(img, (int(new_x1_left), int(y_min)), (int(new_x2_left), y_max), color, 5)\n",
    "    cv2.line(img, (int(new_x1_right), int(y_min)), (int(new_x2_right), y_max), color, 5)\n",
    "    \n",
    "    return (line1, line2)\n",
    "\n",
    "\n",
    "def get_single_line(lines, y_min, y_max):\n",
    "\n",
    "    points = []\n",
    "    total_slope = 0\n",
    "    total_y_intercept = 0\n",
    "    n = len(lines)\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            slope = (y2 - y1)/(x2 - x1)\n",
    "            total_slope += slope\n",
    "            total_y_intercept += (y1 - slope * x1)\n",
    "    \n",
    "    average_slope = total_slope/n\n",
    "    average_y_intercept = total_y_intercept/n\n",
    "    \n",
    "    x1 = int((y_min - average_y_intercept)/average_slope)\n",
    "    x2 = int((y_max - average_y_intercept)/average_slope)\n",
    "    \n",
    "    return (x1, y_min,x2, y_max)\n",
    "\n",
    "def draw_lines2(img, lines, color=[255, 0, 0], thickness=5):\n",
    "    \n",
    "    y_min = int(img.shape[0] * 0.7) \n",
    "    y_max = img.shape[0]\n",
    "\n",
    "    right_lines = []\n",
    "    left_lines = []\n",
    "    \n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            slope = (y2-y1)/(x2-x1)\n",
    "            if slope > 0.5 and slope < 0.9:\n",
    "                left_lines.append(line)\n",
    "            elif slope < -0.5 and slope > -0.9:\n",
    "                right_lines.append(line)\n",
    "    \n",
    "    line1 = None\n",
    "    line2 = None\n",
    "    # to avoid div by 0\n",
    "    if(len(left_lines) > 0):\n",
    "        line1 = get_single_line(left_lines, y_min, y_max)\n",
    "        cv2.line(img, (line1[0], line1[1]), (line1[2], line1[3]), color, thickness)\n",
    "\n",
    "    if(len(right_lines) > 0):\n",
    "        line2 = get_single_line(right_lines, y_min, y_max)\n",
    "        cv2.line(img, (line2[0], line2[1]), (line2[2], line2[3]), color, thickness)\n",
    "    \n",
    "    if line2 == None or line2 == None:\n",
    "        return None\n",
    "    \n",
    "    return (line1, line2)\n",
    "\n",
    "    \n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    \"\"\"\n",
    "    `img` should be the output of a Canny transform.\n",
    "        \n",
    "    Returns an image with hough lines drawn.\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((*img.shape, 3), dtype=np.uint8)\n",
    "#     print(lines)\n",
    "#     line_img = np.zeros(img.shape, dtype=np.uint8)\n",
    "#     plt.imshow(lines)\n",
    "    lines = draw_lines2(line_img, lines)\n",
    "#     plt.imshow(line_img)\n",
    "    return lines, line_img\n",
    "\n",
    "# Python 3 has support for cool math symbols.\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., λ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "    \n",
    "    `initial_img` should be the image before any processing.\n",
    "    \n",
    "    The result image is computed as follows:\n",
    "    \n",
    "    initial_img * α + img * β + λ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)\n",
    "\n",
    "def get_blank_image(image):\n",
    "    \"\"\"\n",
    "        Return a blank image with the same dimensions as\n",
    "        the input image\n",
    "    \"\"\"\n",
    "    return np.zeros(image.shape, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    # NOTE: The output you return should be a color image (3 channel) for processing video below\n",
    "    # TODO: put your pipeline here,\n",
    "    # you should return the final output (image with lines are drawn on lanes)\n",
    "#     img_gray = grayscale(image)\n",
    "    blur_gray = gaussian_blur(image, 5)\n",
    "#     edges = canny(blur_gray, 50, 150)\n",
    "    imshape = image.shape\n",
    "    \n",
    "    bottom_left = (image.shape[1] * 0.15, image.shape[0])\n",
    "    bottom_right = (image.shape[1] * 0.93, image.shape[0])\n",
    "\n",
    "    top_left = (image.shape[1] * 0.4 , image.shape[0]/2)\n",
    "    top_right = (image.shape[1] * 0.6 , image.shape[0]/2)\n",
    "#     print(bottom_left, bottom_right, top_left, top_right)\n",
    "    vertices = np.array([[bottom_left, top_left, top_right, bottom_right]], dtype=np.int32)\n",
    "#     vertices = np.array([[(0,imshape[0]),(560, 410), (630, 410), (imshape[1],imshape[0])]], dtype=np.int32)\n",
    "    masked_edges = region_of_interest(blur_gray, vertices)\n",
    "    lines, line_img = hough_lines(masked_edges, 1, np.pi/180, 30, min_line_len=1, max_line_gap=5)\n",
    "#     print(lines.shape)\n",
    "#     colored_lines_image = np.dstack((lines, get_blank_image(lines), get_blank_image(lines)))\n",
    "#     plt.imshow(lines)\n",
    "#     print(lines.shape)\n",
    "#     print(image.shape)\n",
    "#     plt.imshow(image, cmap='gray')\n",
    "#     image = np.dstack((image, np.zeros(image.shape), np.zeros(image.shape)))\n",
    "#     result = weighted_img(lines, image)\n",
    "    return lines, line_img\n",
    "\n",
    "lines, lines_img = process_image(combined_binary)\n",
    "print(lines)\n",
    "undistorted_image = undistort(image_to_test, dist, mtx)\n",
    "final_image = weighted_img(lines_img, undistorted_image)\n",
    "plt.imshow(final_image)\n",
    "# imsave(\"./output_images/hough_lines.png\", final_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation matrix and warping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPerspectiveTransformMatrx(lines, undistorted_image):\n",
    "    \n",
    "#     print(lines)\n",
    "    if lines == None:\n",
    "        return undistorted_image, undistorted_image\n",
    "    line1 = lines[0]\n",
    "    line2 = lines[1]\n",
    "#     print(line1[0])\n",
    "#     print(line2)\n",
    "    offset = undistorted_image.shape[0] * 0.3\n",
    "    # bottom left, top left, top right, bottom right\n",
    "    src = np.float32([[line1[2], line1[3]], [line1[0], line1[1]], [line2[0], line2[1]], [line2[2], line2[3]]]);\n",
    "    dst = np.float32([[line1[2], line1[3]], [line1[2], offset], [line2[2], offset], [line2[2], line2[3]]]);\n",
    "#     print(src)\n",
    "#     print(dst)\n",
    "    \n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    \n",
    "    \n",
    "    return M, Minv\n",
    "\n",
    "def getWarpedImage(img, matrix):\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    warped = cv2.warpPerspective(img, matrix, img_size, flags=cv2.INTER_LINEAR)\n",
    "    return warped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M, Minv = getPerspectiveTransformMatrx(lines, undistorted_image)\n",
    "warped_image = getWarpedImage(combined_binary, M)\n",
    "warped_image_input = getWarpedImage(undistorted_image, M)\n",
    "plot_on_subplots([warped_image, warped_image_input], [\"warped binary\", \"warped origginal\"], cmap='gray')\n",
    "# pylab.savefig(\"./output_images/warped.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "histogram = np.sum(warped_image[warped_image.shape[0]/2:,:], axis=0)\n",
    "plt.plot(histogram)\n",
    "pylab.savefig(\"histogram.png\")\n",
    "# imsave(\"./output_images/histogram.png\", histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lines_base(image):\n",
    "    histogram = np.sum(image[image.shape[0]/2:,:], axis=0)\n",
    "    indexes = find_peaks_cwt(histogram, np.arange(1, 550))\n",
    "    return [(indexes[0], image.shape[0]), (indexes[-1], image.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "line_base = get_lines_base(warped_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(line_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding pixels and fitting polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_lane_pixels(image, lane_base):\n",
    "    window_size = 100\n",
    "    x_base = lane_base[0]\n",
    "    X_avg = x_base\n",
    "    y_bottom = image.shape[0]\n",
    "    y_top = y_bottom - window_size\n",
    "    print(y_bottom)\n",
    "    print(y_top)\n",
    "    x, y  = [], []\n",
    "    win_left = x_base - window_size/2\n",
    "    win_right = x_base + window_size/2\n",
    "    last = False\n",
    "    \n",
    "    win_bottom = y_bottom\n",
    "    win_top = y_top\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        diff = 0.0\n",
    "        if X_avg != x_base:\n",
    "            diff = x_base - X_avg\n",
    "            print(diff)\n",
    "            x_base = X_avg\n",
    "         \n",
    "        print(\"win_left: \" + str(win_left))\n",
    "        print(\"win_right: \" + str(win_right))\n",
    "        \n",
    "        win_left = win_left - diff\n",
    "        win_right = win_right - diff\n",
    "        \n",
    "        print(\"win_left: \" + str(win_left))\n",
    "        print(\"win_right: \" + str(win_right))\n",
    "        \n",
    "        if win_left < 0:\n",
    "            win_left == 0\n",
    "\n",
    "        if win_left > image.shape[1] or win_right < 0:\n",
    "            break;\n",
    "            \n",
    "        if win_right > image.shape[1]:\n",
    "            win_right = image.shape[1]\n",
    "\n",
    "            \n",
    "        window = image[int(win_top):int(win_bottom), int(win_left):int(win_right)]\n",
    "        plt.imshow(window)\n",
    "#         break;\n",
    "#         print(window)\n",
    "        print(window.shape)\n",
    "        xw, yw = np.where(window == 1)\n",
    "        print(xw)\n",
    "        X_avg = np.average(xw) + win_left\n",
    "        print(\"X_Avg: \" + str(X_avg))\n",
    "        x.append(xw)\n",
    "        y.append(yw)\n",
    "        \n",
    "        print(\"last: \" + str(last))\n",
    "        if last:\n",
    "            break;\n",
    "            \n",
    "        win_bottom -= window_size\n",
    "        win_top -= window_size\n",
    "        \n",
    "        print(\"Win_top: \"  + str(win_top))\n",
    "        if win_top < 0:\n",
    "            win_top = 0\n",
    "            last = True\n",
    "    \n",
    "    \n",
    "    return x, y\n",
    "\n",
    "def get_lane_pixels2(image, lane_base):\n",
    "    window_size = 150 * 2\n",
    "    \n",
    "    x_base = lane_base[0]\n",
    "    \n",
    "    if(x_base > window_size):\n",
    "        window_low = x_base - window_size/2\n",
    "    else:\n",
    "        window_low = 0\n",
    "        \n",
    "    window_high = x_base + window_size/2\n",
    "    \n",
    "#     plt.imshow(image)\n",
    "    window = image[:, window_low:window_high]\n",
    "#     plt.imshow(window)\n",
    "    y, x = np.where(window == 1)\n",
    "    \n",
    "#     print(window_low)\n",
    "    x += np.uint64(window_low)\n",
    "    \n",
    "    return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "left_line, right_line = line_base\n",
    "# plt.imshow(warped_image)\n",
    "left_pixels = get_lane_pixels2(warped_image, left_line)\n",
    "right_pixels = get_lane_pixels2(warped_image, right_line)\n",
    "print(right_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_curved_poly(y, x, degree=2):\n",
    "    line_fit = np.polyfit(y, x, degree)\n",
    "#     print(y.shape)\n",
    "#     y = np.append(y, 719)\n",
    "#     print(y.shape)\n",
    "#     print(np.max(y))\n",
    "    line_fitx = line_fit[0]*y**2 + line_fit[1]*y + line_fit[2]\n",
    "    return (line_fit, line_fitx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_curved_line(left_pixels, right_pixels, left_line, right_line):\n",
    "\n",
    "    mark_size = 3\n",
    "    plt.xlim(0, 1280)\n",
    "    plt.ylim(0, 720)\n",
    "    plt.plot(left_pixels[0], left_pixels[1], 'o', color='red', markersize=mark_size)\n",
    "    plt.plot(right_pixels[0], right_pixels[1], 'o', color='blue', markersize=mark_size)\n",
    "    plt.plot(left_line, left_pixels[1], color='green', linewidth=3)\n",
    "    plt.plot(right_line, right_pixels[1],color='green', linewidth=3)\n",
    "#     plt.plot(left_line, y_left, color='green', linewidth=3)\n",
    "#     plt.plot(right_line, y_right, color='green', linewidth=3)\n",
    "    plt.gca().invert_yaxis() \n",
    "#     pylab.savefig(\"./output_images/curved_lines.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "left_line_curve = get_curved_poly(left_pixels[1], left_pixels[0], 2)\n",
    "right_line_curve = get_curved_poly(right_pixels[1], right_pixels[0], 2)\n",
    "plot_curved_line(left_pixels, right_pixels, left_line_curve[1], right_line_curve[1])\n",
    "# draw_curved_line(warped_image, left_line_curve[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(left_line_curve[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.xlim(0, 1280)\n",
    "plt.ylim(0, 720)\n",
    "plt.plot(left_line_curve[1], left_pixels[1], color='green', linewidth=3)\n",
    "plt.plot(right_line_curve[1], right_pixels[1],color='green', linewidth=3)\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "y_max_l = 719\n",
    "line_fitx_l = left_line_curve[0][0]*y_max_l**2 + left_line_curve[0][1]*y_max_l + left_line_curve[0][2]\n",
    "#     print(line_fitx)\n",
    "\n",
    "y_max_r = 719\n",
    "line_fitx_r = right_line_curve[0][0]*y_max_r**2 + right_line_curve[0][1]*y_max_r + right_line_curve[0][2]\n",
    "#     print(line_fitx_r)\n",
    "\n",
    "lane_center = (line_fitx_l + line_fitx_r)/2\n",
    "actual_center = image.shape[1]/2\n",
    "\n",
    "diff = lane_center - actual_center\n",
    "diff = diff*3.7/700\n",
    "center_txt = None\n",
    "if(diff > 0):\n",
    "    # right\n",
    "    center_txt = \"Vehicle is \" + str(round(diff, 2)) + \"m right of center\"\n",
    "else:\n",
    "    # left\n",
    "    center_txt = \"Vehicle is \" + str(round(-1*diff, 2)) + \"m left of center\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caluclating Radius curvature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_rad_curvature(left_fit, right_fit, left_pixels, right_pixels):\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    \n",
    "    y_eval_left = np.max(left_pixels[1])\n",
    "    y_eval_right = np.max(right_pixels[1])\n",
    "    \n",
    "#     print(y_eval_right)\n",
    "    \n",
    "    fit_left = np.polyfit(left_pixels[1]*ym_per_pix, left_pixels[0]*xm_per_pix, 2)\n",
    "    fit_right = np.polyfit(right_pixels[1]*ym_per_pix, right_pixels[0]*xm_per_pix, 2)\n",
    "    \n",
    "    left_curverad = ((1 + (2*fit_left[0]*y_eval_left*ym_per_pix + fit_left[1])**2)**1.5) / np.absolute(2*fit_left[0])\n",
    "    right_curverad = ((1 + (2*fit_right[0]*y_eval_right*ym_per_pix + fit_right[1])**2)**1.5) / np.absolute(2*fit_right[0])\n",
    "    \n",
    "#     print(left_curverad, right_curverad)\n",
    "    return left_curverad, right_curverad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "left_curverad, right_curverad = calculate_rad_curvature(left_line_curve[0], right_line_curve[0], left_pixels, right_pixels)\n",
    "print(left_curverad, right_curverad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final unwarping of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def final_transform(warped_image, undist_image, left_pixels, right_pixels, left_line_curve, right_line_curve, Minv):\n",
    "    warp_zero = np.zeros_like(warped_image).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "#     print\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "#     print(left_pixels[1])\n",
    "#     left_pixels[1].append(719)\n",
    "#     l_p = np.append(left_pixels[1], [719])\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_line_curve[1], left_pixels[1]]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_line_curve[1], right_pixels[1]])))])\n",
    "#     print(pts_left)\n",
    "#     print(pts_right)\n",
    "    y = 719\n",
    "    \n",
    "    line_fitx_l = left_line_curve[0][0]*y**2 + left_line_curve[0][1]*y + left_line_curve[0][2]\n",
    "    line_fitx_r = right_line_curve[0][0]*y**2 + right_line_curve[0][1]*y + right_line_curve[0][2]\n",
    "    \n",
    "#     print(line_fitx_l)\n",
    "#     print(line_fitx_r)\n",
    "    new_pts_left = np.append(pts_left[0],[[line_fitx_l, y]], axis=0)\n",
    "    new_pts_right = np.append([[line_fitx_r, y]], pts_right[0], axis=0)\n",
    "    \n",
    "    new_left = []\n",
    "    new_left.append(new_pts_left)\n",
    "#     print(np.asarray(new_left))\n",
    "    new_right = []\n",
    "    new_right.append(new_pts_right)\n",
    "#     print(np.asarray(new_right))\n",
    "#     print(new_left)\n",
    "#     print(new_right)\n",
    "    pts = np.hstack((np.asarray(new_left), np.asarray(new_right)))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (image.shape[1], image.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undist_image, 1, newwarp, 0.3, 0)\n",
    "    return result;\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "warp_zero = np.zeros_like(warped_image).astype(np.uint8)\n",
    "color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "# Recast the x and y points into usable format for cv2.fillPoly()\n",
    "pts_left = np.array([np.transpose(np.vstack([left_line_curve[1], left_pixels[1]]))])\n",
    "pts_right = np.array([np.flipud(np.transpose(np.vstack([right_line_curve[1], right_pixels[1]])))])\n",
    "pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "# Draw the lane onto the warped blank image\n",
    "cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "# Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "newwarp = cv2.warpPerspective(color_warp, Minv, (image.shape[1], image.shape[0])) \n",
    "# Combine the result with the original image\n",
    "result = cv2.addWeighted(undistorted_image, 1, newwarp, 0.3, 0)\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "cv2.putText(result, 'Radius of curvature is = ' + str(round(left_curverad, 2)) + \"(m)\", (50,50), font, 1.5,(255,255,255), 3)\n",
    "cv2.putText(result, center_txt, (50,100), font, 1.5,(255,255,255), 3)\n",
    "plt.imshow(result)\n",
    "# imsave(\"./output_images/result.png\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The whole pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_image_advanced(image):\n",
    "    \n",
    "    # undistorted\n",
    "    undist = undistort(image, dist, mtx)\n",
    "    \n",
    "    # thresholded binary\n",
    "    combined_binary = get_thresholded_image(undist)\n",
    "    \n",
    "    # hough lines\n",
    "    lines, lines_img = process_image(combined_binary)\n",
    "#     final_image = weighted_img(lines_img, undist)\n",
    "#     plt.imshow(final_image)\n",
    "    \n",
    "    # perspective transform\n",
    "#     M, Minv = getPerspectiveTransformMatrx(lines, undist)\n",
    "    warped_image = getWarpedImage(combined_binary, M)\n",
    "    \n",
    "    # get left and right lines pixels\n",
    "    line_base = get_lines_base(warped_image)\n",
    "    left_line, right_line = line_base\n",
    "    left_pixels = get_lane_pixels2(warped_image, left_line)\n",
    "    right_pixels = get_lane_pixels2(warped_image, right_line)\n",
    "    \n",
    "    # fit left right pixels to a order 2 polynomial\n",
    "    left_line_curve = get_curved_poly(left_pixels[1], left_pixels[0], 2)\n",
    "    right_line_curve = get_curved_poly(right_pixels[1], right_pixels[0], 2)\n",
    "    \n",
    "    y_max_l = 719\n",
    "    line_fitx_l = left_line_curve[0][0]*y_max_l**2 + left_line_curve[0][1]*y_max_l + left_line_curve[0][2]\n",
    "#     print(line_fitx)\n",
    "\n",
    "    y_max_r = 719\n",
    "    line_fitx_r = right_line_curve[0][0]*y_max_r**2 + right_line_curve[0][1]*y_max_r + right_line_curve[0][2]\n",
    "#     print(line_fitx_r)\n",
    "    \n",
    "    lane_center = (line_fitx_l + line_fitx_r)/2\n",
    "    actual_center = image.shape[1]/2\n",
    "    \n",
    "    diff = lane_center - actual_center\n",
    "    diff = diff*3.7/(line_fitx_r - line_fitx_l)\n",
    "    center_txt = None\n",
    "    if(diff > 0):\n",
    "        # right\n",
    "        center_txt = \"Vehicle is \" + str(round(diff, 2)) + \"m right of center\"\n",
    "    else:\n",
    "        # left\n",
    "        center_txt = \"Vehicle is \" + str(round(-1*diff, 2)) + \"m left of center\"\n",
    "    # get left and right radius of the curvature in meters\n",
    "    left_curverad, right_curverad = calculate_rad_curvature(left_line_curve[0], right_line_curve[0], left_pixels, right_pixels)\n",
    "    \n",
    "    # final transformation back to original image\n",
    "    final_image = final_transform(warped_image, undist, left_pixels, right_pixels, left_line_curve, right_line_curve, Minv)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(final_image, 'Radius of curvature is = ' + str(round(left_curverad, 2)) + \"(m)\", (50,50), font, 1.5,(255,255,255), 3)\n",
    "    cv2.putText(final_image, center_txt, (50,100), font, 1.5,(255,255,255), 3)\n",
    "    return final_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_image = process_image_advanced(raw_images[5])\n",
    "plt.imshow(final_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "white_output = 'project_video_out_2.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "white_clip = clip1.fl_image(process_image_advanced) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
